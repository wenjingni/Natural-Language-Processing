{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic-modelling with UMAP and HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SentenceBert (sBert) to embed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import umap\n",
    "import torch\n",
    "import hdbscan\n",
    "import hyperopt as hp\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from functools import partial\n",
    "from hyperopt import space_eval\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in sentences from a csv\n",
    "data = pd.read_csv('all-comments-with-time.txt',sep='\\t',encoding='utf-8')\n",
    "data = data.dropna()\n",
    "time = list(data['MovieTime'])\n",
    "texts = list(data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a suitable model for sentence transformer\n",
    "#use 'cuda' if it exists\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "embeddings = model.encode(texts, show_progress_bar=True,device = device)\n",
    "with open(\"all-embeddings-time-based.pkl\", \"wb\") as fOut:\n",
    "    pickle.dump({'sentences': data, 'embeddings':embeddings},fOut,protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using UMAP to reduce dimensionality, then using HDBSCAN for sentence clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_pickle('samples_of_embeddings.pkl')\n",
    "embeds = list(samples['Embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=5, \n",
    "                            metric='cosine').fit_transform(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'min_samples': 500, 'min_cluster_size': 300,'metric': 'manhattan', 'cluster_selection_method': 'eom'\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=300,\n",
    "                          min_samples = 500,\n",
    "                          metric='manhattan',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(list(embeddings))\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize clusters (This is calculated by following parametersï¼š'min_samples': 500, 'min_cluster_size': 300,'metric': 'manhattan', 'cluster_selection_method': 'eom')\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "clustered_lbs = clustered['labels']\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "# for i, txt in enumerate(list(clustered_lbs)):\n",
    "#     plt.annotate(txt, (clustered.iloc[i].x, clustered.iloc[i].y))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using random search to seek for better parameters for clustering\n",
    "\n",
    "hdb = hdbscan.HDBSCAN(gen_min_span_tree=True).fit(umap_embeddings)\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'min_samples': [10,30,50,60,100],\n",
    "              'min_cluster_size':[100,200,300,400,500,600],  \n",
    "              'cluster_selection_method' : ['eom','leaf'],\n",
    "              'metric' : ['euclidean','manhattan'] \n",
    "             }\n",
    "\n",
    "#validity_scroer = \"hdbscan__hdbscan___HDBSCAN__validity_index\"\n",
    "validity_scorer = make_scorer(hdbscan.validity.validity_index,greater_is_better=True)\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(hdb\n",
    "                                   ,param_distributions=param_dist\n",
    "                                   ,n_iter=n_iter_search\n",
    "                                   ,scoring=validity_scorer \n",
    "                                   ,random_state=np.random.RandomState(42))\n",
    "\n",
    "random_search.fit(umap_embeddings)\n",
    "\n",
    "\n",
    "print(f\"Best Parameters {random_search.best_params_}\")\n",
    "print(f\"DBCV score :{random_search.best_estimator_.relative_validity_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2afdca8f70b9f9f77c5d249cdce1221fa9bba527d701426b4b260e465f8ff569"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
